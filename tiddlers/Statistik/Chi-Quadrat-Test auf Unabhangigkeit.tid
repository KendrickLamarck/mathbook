created: 20200622220847032
creator: Leander
modified: 20200702202037629
modifier: Leander
revision: 0
tags: Test
title: Chi-Quadrat-Test auf Unabhängigkeit
type: text/vnd.tiddlywiki

Betrachte das statistische Modell $$(E^\N,\mathcal P(E)^{\otimes \N},(\prob_\vartheta)_{\vartheta \in \varTheta})$$ mit

* $$E = A \times B,$$ wobei $$A = \{1,\dots,a\},\ B = \{1,\dots,b\}.$$
* $$\varTheta = \{\vartheta = (\vartheta(ij)) \in \openI{0,1}^E : \sum \vartheta(ij) = 1\},$$
* $$\prob_\vartheta(X_k = ij) = \vartheta(ij).$$

Bezeichne mit
$$\vartheta^A = (\vartheta^A(i))_{i \in A},$$ wobei
$$\vartheta^A(i) = \sum_{j \in B} \vartheta(ij)$$
und $$\vartheta^B$$ analog die Randverteilungen. Die Merkmale sind also unabhängig genau dann wenn
$$\vartheta(ij) = \vartheta^A(i)\vartheta^B(j)$$
für alle $$ij \in E.$$

Wir testen die Nullhypothese
$$H_0\colon \vartheta = \vartheta^A \otimes \vartheta^B$$ gegen
$$H_1\colon \vartheta \ne \vartheta^A \otimes \vartheta^B,$$ also
$$\varTheta_0 = \{\alpha \otimes \beta : \alpha \in \varTheta_A,\,\beta \in \varTheta_B\}$$
mit
$$\varTheta_A = \{\alpha \in \openI{0,1}^A : \sum\alpha(i) = 1\}$$
und $$\varTheta_B$$ analog.
Definiere analog zum [[Chi-Quadrat-Anpassungstest]] die absoluten und relativen Häufigkeiten $$h_n(ij)$$ und $$l_n(ij)$$ sowie die Randverteilungen
$$(l_n^A(i))_{i \in A}$$ mit
$$l_n^A(i) = \sum_{j \in B} l_n(ij)$$
und $$l_n^B,h_n^A,h_n^B$$ analog.  Zum Beispiel:

|Merkmale  | $$a_1$$      | $$a_2$$      | $$a_3$$      | &sum; |
| $$b_1$$  | $$h_n(1,1)$$ | $$h_n(1,2)$$ | $$h_n(1,3)$$ | $$h_n^A(1)$$ |
| $$b_2$$  | $$h_n(2,1)$$ | $$h_n(2,2)$$ | $$h_n(2,3)$$ | $$h_n^A(2)$$ |
| &sum; | $$h_n^B(1)$$ | $$h_n^B(2)$$ | $$h_n^B(3)$$ | $$n$$ |

''Ansatz 1.''
Der verallgemeinerte Likelihood-Quotient:
$$\begin{aligned}
R_n &\coloneqq \frac{
  \sup_{\vartheta \in \varTheta_1}
  \prod_{ij \in E} \vartheta(ij)^{h_n(ij)}
}{
  \sup_{\alpha\otimes\beta \in \varTheta_0}
  \prod_{ij \in E} (\alpha(i)\beta(j))^{h_n(ij)}
} 
= \prod_{ij \in E}
  \left(\frac{l_n(ij)}{l_n^A(i)l_n^B(j)}\right)^{h_n(ij)} \\ \implies
\log R_n &= n\sum_{ij \in E} l_n(ij)\log\frac{l_n(ij)}{l_n^A(i)l_n^B(j)}
= n \Eta(l_n \mid l_n^A \otimes l_n^B).
\end{aligned}$$
Der verallgemeinerte Likelihood-Quotiententest hat dann die Form $$\varphi_n = \mathbf 1_{\{\log R_n > c\}}.$$

''Ansatz 2.''
Sei
$$\begin{aligned}
D_n &\coloneqq \sum_{ij \in E} \frac{
  (h_n(ij) - h_n^A(i)h_n^B(j)/n)^2
}{
  h_n^A(i)h_n^B(j)/n
} \\ &=
n\sum_{ij \in E} l_n^A(i) l_n^B(j)
\left(\frac{l_n(ij)}{l_n^A(i) l_n^B(j)}-1\right)^2 \\ &=
n\sum_{ij \in E}\frac{l_n(ij)^2}{l_n^A(i)l_n^B(j)} - n
\end{aligned}$$
(die letzte Form eignet sich gut zur Berechnung). Definieren wir
$$
\tilde h_n = \left(
  \frac{h_n(ij) - n\, l_n^A(i) l_n^B(j)}{\sqrt{n\, l_n^A(i) l_n^B(j)}}
\right)_{ij \in E,}
$$
so gilt $$D_n = \|\tilde h_n\|^2.$$
Ein Test $$\varphi_n = \mathbf 1_{\{D_n > c\}}$$ heißt dann ein //Chiquadrat-Test auf Unabhängigkeit// nach $$n$$ Beobachtungen.

* Wie beim [[Chi-Quadrat-Anpassungstest]] stimmen $$D_n$$ und $$R_n$$ auf der Nullhypothese approximativ überein.

* <div>Verallgemeinerter Satz von Pearson: Unter $$\P_\rho$$ für $$\rho = \alpha \otimes \beta \in \varTheta_0$$ gilt
$$
D_n \xrightarrow[n\to\infty]{d} \chi^2_{(a-1)(b-1)}.
$$</div>

* Wieder können wir bei großen $$n$$ das $$c$$ als $$\alpha$$-Fraktil der $$\chi^2_{(a-1)(b-1)}$$-Verteilung wählen, damit der Test ungefähr das Niveau $$\alpha$$ erreicht.