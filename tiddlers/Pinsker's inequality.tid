created: 20230925205525708
modified: 20230925205725569
tags: [[Machine learning]]
title: Pinsker's inequality
type: text/vnd.tiddlywiki

For $$\mu, \nu \in \probmeasures(\R^d)$$, we have
$$
\dTV(\mu, \nu) \le \sqrt{2\dKL(\mu \mmid \nu)}.
$$
Hence the topology defined on $$\probmeasures(\R^d)$$ by the [[KL-divergence|Relative Entropie]] is stronger than the topology defined by the [[total variation|Total variation]] and [[Radon distance|Radon-Norm]].